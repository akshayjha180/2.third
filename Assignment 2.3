Explain in detail: 
● All components of Hadoop 1.x
  Apache Hadoop 1.x or earlier versions are using the following Hadoop Architecture. It is a Hadoop 1.x High-level Architecture.
  Both Master Node and Slave Nodes contain two Hadoop Components:
• HDFS Component
• MapReduce Component
• Master Node’s HDFS component is also known as “Name Node”.
• Slave Node’s HDFS component is also known as “Data Node”.
• Master Node’s “Name Node” component is used to store Meta Data.
• Slave Node’s “Data Node” component is used to store actual our application Big Data.
• HDFS stores data by using 64MB size of “Data Slots” or “Data Blocks”.
• Master Node’s MapReduce component is also known as “Job Tracker”.
• Slave Node’s MapReduce component is also known as “Task Tracker”.
• Master Node’s “Job Tracker” will take care assigning tasks to “Task Tracker” and receiving results from them.
  Slave Node’s MapReduce component “Task Tracker” contains two MapReduce Tasks:
• Map Task
• Reduce Task

● Further detailed explanation -:  
● NameNode
• Contains the Hadoop FileSystem Tree and other metadata information about files and directories.
• Contains in-memory mapping of which blocks are stored in which datanode.
  Secondary NameNode
• Performs house-keeping activities for NameNodes, like the periodic merging of namespace and edits.
• This is not a back up for a NameNode.
● DataNode
• Stores actual data blocks of files in HDFS on its own local disk.
• Sends signals to the NameNode periodically (called as Heartbeat) to verify whether it is active.
• Sends block reporting to the NameNode on the cluster startup as well as periodically at every 10th Heartbeat.
• The DataNodes are the workhorses of a system.
• They perform all the block operations including periodic checksum. They receive instructions from the name node of
  where to put the blocks and how to put them.
● Hadoop Framework Description 23
  JobTracker (Not present in Hadoop 2.x)
• Controls the overall execution of the MapReduce jobs
  TaskTracker (Not present in Hadoop 2.x)
• Runs individual MapReduce jobs on DataNodes
• Periodically communicates with the JobTracker to give updates and receive instructions
